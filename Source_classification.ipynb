{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neuron Network in Action: Source Classification\n",
    "\n",
    "### Comp Club 4/17/19\n",
    "Shih-Yi Tseng\n",
    "\n",
    "<hr style=\"height:2pt\">\n",
    "\n",
    "In this exercise, we will learn how to build a CNN to classify sources for 2-photon calcium imaging data. In 2-photon calcium imaging, we collect images of field of views through the microscope, and process those images (or movies) afterward to extract activity traces of ROIs, or what we call \"sources\", before doing further analysis. Open source softwares such as Suite2P (https://github.com/cortex-lab/Suite2P) or CNMF (https://github.com/flatironinstitute/CaImAn) are available for processing the images and extract sources, and at the end of this pipeline, we classify the sources into different categories and determine what we want to include in the downstream analysis.\n",
    "\n",
    "Here is an example of the collection of all sources in one imaging plane of L2/3 cortex: \n",
    "![source](source_images.tif)\n",
    "\n",
    "Our task is to classify these sources into 4 categories using a CNN:\n",
    "\n",
    "- **Class 0: Cell bodies**\n",
    "\n",
    "- **Class 1: Small, vertical processes**\n",
    "\n",
    "- **Class 2: Complex, horizontal processes or out-of-focus cells**\n",
    "\n",
    "- **Class 3: Junk**\n",
    "\n",
    "You'll see some examples in the following section.\n",
    "\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libaries and functions\n",
    "\n",
    "***\n",
    "\n",
    "First we import some libraries and functions that we'll be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(11)\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and visualize the sources\n",
    "***\n",
    "\n",
    "Run this cell to load data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sources.pkl','rb') as file:\n",
    "    sources = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains 16000 images of different sources (height = 25, width = 25, number of channels = 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 4000 examples for each class (arranged in class order). So we can recreate the class labels (response variables) for each image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size = 4000\n",
    "class_name = ['cell','vertical process','complex process', 'junk']\n",
    "labels = [n * np.ones((class_size,1)) for n in range(len(class_name))]\n",
    "labels = np.concatenate(labels, axis = 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also do some visualization and see how these images look like. Try to change the `n_source` and look at different sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_source = 0\n",
    "plt.imshow(sources[n_source,:,:,0],cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples(class_id, n_samples = 16):\n",
    "    sample_id = class_id * class_size + np.random.choice(class_size, size = (n_samples,))\n",
    "    image_list = [sources[ii,:,:,0] for ii in sample_id]\n",
    "    image_stack = np.hstack(image_list)\n",
    "    plt.figure(figsize = (20,3))\n",
    "    plt.imshow(image_stack, cmap = 'gray', vmin=None, vmax=0.4)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(class_name[class_id])\n",
    "    \n",
    "for n_class in range(4):\n",
    "    plot_samples(n_class, n_samples = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training/validation/test samples\n",
    "***\n",
    "As a standard practice for building machine learning models, we split our data into 3 portions: training, validation, and test sets using **train_test_split** funciton (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) from sklearn. It also shuffle the data for you, conveniently.\n",
    "\n",
    "Here we use 80% of samples for training, 10% for validation and 10% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split 80-20 for train/test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(sources, labels, test_size = 0.2)\n",
    "\n",
    "# further split the 20% in half for validation and true test set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have to convert the labels into dummy variables (one column for each class) using keras utility function **to_categorical**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert y to categorical\n",
    "n_classes = 4\n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, n_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, n_classes)\n",
    "\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image augmentation using ImageDataGenerator\n",
    "***\n",
    "\n",
    "For training CNN on image classification, one commonly used method to prevent overfitting is to do image augmentation. We can manipulate the training images in several ways to create a larger training set, such as random rotations, shifts, zooms, etc. Here we are using the **ImageDataGenerator** from Keras for the augmentation.\n",
    "\n",
    "You can find more options and description for the ImageDataGenerator from the documentation: https://keras.io/preprocessing/image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range = 360,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1,\n",
    "    zoom_range = 0.1,\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True,\n",
    "    validation_split = 0.1)\n",
    "\n",
    "train_datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the CNN model\n",
    "***\n",
    "We use Keras **Sequential** mode to build our model, in which we can stack layers on top of each other. And then we choose the **optimizer** we want to use, and **compile the model** with the optimizer, the loss function, and the metrics for evaluation. We can print out the summary of the model after compiling it.\n",
    "\n",
    "\n",
    "Documentation for Sequential: https://keras.io/models/sequential/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding = 'same', input_shape = X_train.shape[1:], activation = 'relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dense(4, activation = 'softmax'))\n",
    "\n",
    "# set optimizer\n",
    "opt = keras.optimizers.Adam(lr = 0.01, decay = 0.005)\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss ='categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n",
    "\n",
    "# print out summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "***\n",
    "Before training, we define the batch size and number of epochs. Since we are using the ImageDataGenerator to generate training data, we choose the **fit_generator** function to start fitting process. Other fitting methods are **fit** (feed in all training data at a time) and **train_on_batch** (perform single gradient descent on one batch). \n",
    "\n",
    "The information about the training process is returned as a **history** object. We can inspect the information in the history object and diagnose the training afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "batch_size = 1024\n",
    "epochs = 30\n",
    "\n",
    "history = model.fit_generator(train_datagen.flow(X_train, y_train, batch_size = batch_size),\n",
    "                              steps_per_epoch = X_train.shape[0]/batch_size, \n",
    "                              epochs = epochs,\n",
    "                              validation_data = (X_val, y_val), \n",
    "                              shuffle = True, \n",
    "                              workers = -1, \n",
    "                              verbose = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize training process\n",
    "***\n",
    "In history.history, we can find the loss and accuracy on train/validation data for every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(14,4))\n",
    "ax[0].plot((history.history['loss']), 'r', label='train')\n",
    "ax[0].plot((history.history['val_loss']), 'b' ,label='val')\n",
    "ax[0].set(xlabel = 'Epoch', ylabel = 'Loss', title = 'Training vs. Validation Loss')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot((history.history['acc']), 'r', label='train')\n",
    "ax[1].plot((history.history['val_acc']), 'b' ,label='val')\n",
    "ax[1].set(xlabel = 'Epoch', ylabel = 'Accuracy', title = 'Training vs. Validation Accuracy')\n",
    "ax[1].legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model\n",
    "***\n",
    "Now we use the **evaluate** function to see how our model performs on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.evaluate(X_test, y_test)\n",
    "print('loss = ', result[0], '\\naccuracy =', result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use **predict** function to make prediction. It returns a vector of probability distribution over the 4 classes, so we use **np.argmax** to extract the predicted class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(X_test), axis = 1)\n",
    "print('Average accuracy =', accuracy_score(np.argmax(y_test, axis = 1), y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix\n",
    "***\n",
    "For further inspect the model performance on each class, we typically plot the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use plotting function of confusion matrix from sklearn\n",
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the normalized confusion matrix\n",
    "cm = confusion_matrix(np.argmax(y_test,axis = 1),y_pred)\n",
    "plot_confusion_matrix(cm, class_name, normalize=False)\n",
    "print('Positive predictive value :',np.diag(cm)/np.sum(cm,axis = 0))\n",
    "print('Sensitivity :',np.diag(cm)/np.sum(cm,axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we improve the performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
